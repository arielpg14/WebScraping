{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOwaFB5chqBguSB7YGViEIT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/arielpg14/WebScraping/blob/main/WebScraping.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kg8rBTSFloea"
      },
      "outputs": [],
      "source": [
        "# Instalación de las librerias o dependencias necesarias\n",
        "!pip install beautifulsoup4 requests pandas"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load dependencies\n",
        "import json # modulo para trabajar con archivos JSON\n",
        "import requests # libreria para hacer peticiones HTTP\n",
        "import pandas as pd # libreria para procesar datos, proporciona funciones para analíticas\n",
        "from bs4 import BeautifulSoup as bs # Extraer información de paginas web"
      ],
      "metadata": {
        "id": "-Ycjrg_Clzbl"
      },
      "execution_count": 239,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Función que convierte una lista de elementos en un dataframe de pandas\n",
        "def rowsToDataFrame(rows):\n",
        "    df = pd.DataFrame(rows[1:], columns=rows[0])\n",
        "    return df"
      ],
      "metadata": {
        "id": "VTLG7zMElzeB"
      },
      "execution_count": 240,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Función para extraer los datos de una tabla HTML\n",
        "def processTableData(tbl):\n",
        "    rows = []\n",
        "    for child in tbl.find('tbody').children: # itera los items internos de la tabla [<tr>]\n",
        "        row = []\n",
        "        for td in child: # itera los items internos de la tabla [<td>]\n",
        "            try:\n",
        "                item = td.text.replace('\\n', '') # recupera el texto del elemento [<td>]\n",
        "                if item:\n",
        "                    row.append(item) # Agrega cada elemento de la fila\n",
        "            except:\n",
        "                continue\n",
        "        if len(row) > 0:\n",
        "            rows.append(row) # agrega todos los campos de una fila de la tabla\n",
        "    # print(rows)\n",
        "    return rows"
      ],
      "metadata": {
        "id": "UF8Rgn57lzgU"
      },
      "execution_count": 241,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Función para exxtrar la data de la URL y procesar el contenido HTML\n",
        "def processDataHTML(data):\n",
        "    soup = bs(data['sections'][0]['text'], 'html.parser') # Recupera el item del JSON y lo convierte en contenido HTML\n",
        "    print(soup.prettify())\n",
        "    tbl = soup.find_all('table')[0] # Recupera la tabla del contenido HTML\n",
        "    # print(tbl.prettify())\n",
        "    tblRows = processTableData(tbl) # Ejecuta la función apra porcesar el contenido de la Tabla\n",
        "    return tblRows\n",
        ""
      ],
      "metadata": {
        "id": "ndorc0r0lzir"
      },
      "execution_count": 326,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Read website\n",
        "# r = requests.get('https://www.wikiwand.com/es/Anexo:Tabla_estadística_de_la_Copa_Mundial_de_Fútbol')\n",
        "r = requests.get('https://www.wikiwand.com/mcs-api/en.wikipedia.org/v1/page/mobile-sections-remaining/COVID-19_pandemic_in_South_America')  # Recuperamos el contenido de la web\n",
        "# print(r)\n",
        "table = processDataHTML(json.loads(r.content)) # Formate el contenido en formato JSON\n",
        "df = rowsToDataFrame(table) # ejecuta la funcion para recupera los datos de la tabla como dataframe de Pandas\n",
        "df"
      ],
      "metadata": {
        "id": "NwBtu4gNR1Kv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Guardamos las datos extraidos como archivo CSV\n",
        "# se puede aplcair otras opciones para guardar (Base de datos)\n",
        "df.to_csv('covidSouthAmerica.csv')"
      ],
      "metadata": {
        "id": "Ssy5v4r9Spcm"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}